# Tech Digest - 2026-03-01

### A Tech Blog Diff - ([[WM:TECHBLOG]])

https://techblog.wikimedia.org/2026/02/24/a-tech-blog-diff/

# Summary

The Wikimedia Developer Outreach team is migrating the Tech Blog to Diff, a community news platform that receives approximately 20,000 monthly visits and 1,200 email subscribers. This move aims to increase visibility and support for technical community contributions. All existing Tech Blog posts will be preserved and accessible on Diff with "techblog" tags, and old links will automatically redirect to their new locations. The migration is scheduled to complete in April 2026.

After the migration, the submission process for technical blog posts remains similar, with contributors selecting the "Technology" category and "techblog" tag when submitting through Diff's platform. The Developer Outreach team will continue to review technical submissions before publication. Contributors are asked to hold submissions until the migration is complete.

---

### Interactive explanations - (Simon Willison's Weblog)

https://simonwillison.net/guides/agentic-engineering-patterns/interactive-explanations/#atom-everything

# Summary

Simon Willison discusses how AI-generated code can create "cognitive debt" when developers don't fully understand how it works, potentially slowing progress and limiting their ability to reason about their applications. He advocates for paying down this debt through interactive explanations—a technique he demonstrates by building an animated word cloud visualizer that demonstrates the Archimedean spiral algorithm used for placement.

Using Claude Code, Willison created an interactive HTML tool that animates the word placement process, allowing users to pause, adjust speed, and step through the algorithm frame-by-frame. This visualization successfully clarified how the algorithm works by showing each word being tested for position, spiraling outward from the center until finding a non-overlapping spot. He argues that AI agents can readily produce such explanatory animations on demand, making them a valuable tool for understanding both agent-generated code and existing codebases.

---

### Please, please, please stop using passkeys for encrypting user data - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/27/passkeys/#atom-everything

# Summary

The article warns against using passkeys as a method for encrypting user data, arguing that this practice creates serious risks. Since users frequently lose their passkeys and may not understand that data encrypted with them cannot be recovered if the passkey is lost, this approach is problematic and potentially harmful.

Tim Cappalli advocates that the identity industry should stop promoting passkeys for data encryption while continuing to leverage their strengths as phishing-resistant authentication credentials. The core message is that passkeys should be limited to their intended purpose—secure login—rather than being repurposed for data encryption where key loss has irreversible consequences.

---

### An AI agent coding skeptic tries AI agent coding, in excessive detail - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/27/ai-agent-coding-in-excessive-detail/#atom-everything

# Summary

Max Woolf, a former AI agent coding skeptic, documents his experience using AI coding agents for increasingly ambitious projects, ranging from simple YouTube metadata scrapers to porting Python's scikit-learn machine learning library to Rust. He demonstrates that modern models like Opus 4.6 and Codex 5.3 have become dramatically more capable than their predecessors from just months earlier, successfully completing complex coding tasks that would typically take experienced developers months to accomplish.

Woolf captures the frustration of conveying just how significant this advancement is to skeptics without sounding like an AI hype promoter, noting that the leap in capability is substantial but counterintuitive to many in the industry. The article exemplifies a broader trend of posts celebrating how much AI coding agents have improved since late 2025, with the author himself becoming a convert after witnessing their actual performance on challenging development work.

---

### Free Claude Max for (large project) open source maintainers - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/27/claude-max-oss-six-months/#atom-everything

# Summary

Anthropic is offering free access to Claude Max (their $200/month premium plan) for six months to open source maintainers who meet specific criteria. Eligible maintainers must be primary contributors to public repositories with 5,000+ GitHub stars or 1M+ monthly NPM downloads, with recent activity (commits, releases, or PR reviews within the last 3 months). The program accepts up to 10,000 contributors, though maintainers of less visible but ecosystem-critical projects are encouraged to apply regardless of meeting the strict criteria.

---

### Unicode Explorer using binary search over fetch() HTTP range requests - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/27/unicode-explorer/#atom-everything

# Summary

Simon Willison created a Unicode Explorer prototype that demonstrates HTTP range requests combined with binary search to efficiently query Unicode codepoint metadata from a large file. He collaborated with Claude AI to design the concept and implementation, ultimately deploying an interactive tool that allows users to search for Unicode characters or codepoints and visualize the binary search process across a 76.6MB dataset stored in an S3 bucket via Cloudflare.

The project showcases practical applications of HTTP range request tricks while highlighting a technical insight: range requests are incompatible with HTTP compression due to byte offset conflicts, though CDNs like Cloudflare automatically disable compression when range headers are present. The resulting demo is publicly accessible and demonstrates how binary search can efficiently navigate large, naturally-sorted datasets over the web.

---

### Hoard things you know how to do - (Simon Willison's Weblog)

https://simonwillison.net/guides/agentic-engineering-patterns/hoard-things-you-know-how-to-do/#atom-everything

# Summary

Simon Willison advocates for building and maintaining a personal collection of working code examples and solutions to technical problems—a practice he calls "hoarding." He argues that understanding what's possible in software development requires not just theoretical knowledge but hands-on experience with proven implementations. Willison documents his solutions across his blog, GitHub repositories, and a collection of HTML-based tools, emphasizing that this repository of knowledge becomes increasingly valuable when combined and recombined to solve new problems.

The real power of this approach emerges when paired with coding agents, which can search, retrieve, and synthesize these examples to tackle new challenges. Rather than solving similar problems repeatedly, developers can instruct agents to examine existing working implementations and use them as templates for new tasks—whether fetching source code from URLs, searching local projects, or cloning repositories. This transforms hoarding from a personal productivity technique into a scalable method for leveraging AI agents to solve problems faster and more reliably.

---

### Quoting Andrej Karpathy - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/26/andrej-karpathy/#atom-everything

# Summary

In a quote shared by Simon Willison in February 2026, Andrej Karpathy highlights a dramatic shift in AI-assisted programming, noting that coding agents underwent a fundamental breakthrough in December 2025. Rather than gradual incremental progress, there was a sudden, disruptive leap in capability—models now demonstrate significantly higher quality, better long-term coherence, and greater persistence, enabling them to handle large, complex programming tasks that were previously infeasible.

Karpathy emphasizes that this represents a watershed moment for the programming profession, with AI coding agents transitioning from non-functional tools to genuinely practical assistants capable of powering through substantial development work, fundamentally altering typical programming workflows.

---

### Google API Keys Weren't Secrets. But then Gemini Changed the Rules. - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/26/google-api-keys/#atom-everything

# Summary

Google API keys designed to be public for services like Google Maps became a security vulnerability when Google enabled the Gemini API on the same projects without warning developers. This created a privilege escalation issue where previously harmless public keys could suddenly access sensitive Gemini endpoints and make billable requests. Security researchers found nearly 2,900 exposed API keys capable of accessing Gemini, including some belonging to Google itself that had been deployed years before the Gemini API even existed.

The core problem is that developers were never notified when their API keys' permissions changed, leaving them unaware that credentials once safe to embed publicly were now dangerous secrets. Google is working to revoke affected keys, but developers should audit their own keys to ensure they haven't been compromised.

---

### Quoting Benedict Evans - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/26/benedict-evans/#atom-everything

# Summary

Benedict Evans argues that OpenAI hasn't achieved true product-market fit, as most users engage with the technology only a few times weekly and struggle to find daily use cases—a "capability gap" between what AI models can do and what people actually use them for. OpenAI's advertising initiative serves a dual purpose: it helps cover infrastructure costs for the 90%+ of non-paying users while strategically enabling those users to access more powerful (and expensive) models, with the goal of increasing engagement and finding sustainable value propositions.

---

### tldraw issue: Move tests to closed source repo - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/25/closed-tests/#atom-everything

# Summary

A blog post by Simon Willison discusses tldraw, a collaborative drawing library, that appeared to be moving its test suite to a private repository—ostensibly in response to concerns that comprehensive test suites enable AI agents to recreate open-source projects from scratch. The move reflected worries from commercial open-source projects about intellectual property protection, especially after Cloudflare used AI to port Next.js to Vite in a week.

However, the update clarifies that the issue was largely a joke. The tldraw team acknowledged that moving tests would actually slow down their development, and they emphasized that their real value lies in making good product decisions for users rather than protecting code through obscurity. They remain committed to open-source principles despite operating under a custom license requiring commercial licenses for production use.

---

### Claude Code Remote Control - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/25/claude-code-remote-control/#atom-everything

# Summary

Claude Code has released a new "remote control" feature that allows users to start a remote session on their computer and control it via Claude Code's web, iOS, or desktop interfaces. However, the feature is currently in rough shape, with issues including account permission errors, mandatory action approval (no option to skip permissions), API 500 errors, and poor session termination handling. The author expects these bugs to be resolved quickly.

Additionally, Anthropic announced scheduled task functionality in Cowork (Claude Code's agent sibling), addressing another key feature gap. However, scheduled tasks have a significant limitation: they only run when the user's computer is awake and the desktop app is open, making them less useful for true automation. The author hopes Anthropic is developing a cloud-based version to overcome this constraint.

---

### I vibe coded my dream macOS presentation app - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/25/present/#atom-everything

# Summary

Simon Willison used AI-assisted "vibe coding" to build Present.app, a custom macOS presentation tool, in just 45 minutes the night before giving a talk at Social Science FOO Camp. The lightweight Swift/SwiftUI application (355KB) allows users to create presentations as ordered sequences of URLs, with a sidebar for editing and full-screen presentation mode controlled via arrow keys. A key advantage over his previous browser-based approach is automatic saving—if the app crashes, presentation state is preserved.

Willison expanded the app's capabilities by adding a web server that enables remote control from his phone via Tailscale, allowing him to navigate slides and adjust font size from anywhere. He emphasizes that while the app was quickly built with AI assistance, it solved a real problem he'd wanted solved for years. The project demonstrates how experienced software engineers can use modern LLM tools to expand into unfamiliar languages like Swift, though he notes that domain expertise and existing technical knowledge still provided significant value in the development process.

---

### Quoting Kellan Elliott-McCrea - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/25/kellan-elliott-mccrea/#atom-everything

# Summary

Kellan Elliott-McCrea reflects on the different motivations people have for entering the technology field and how current changes may affect them differently. He contrasts those who entered tech in recent decades primarily for job security or coding enjoyment with earlier generations like himself who were drawn to the sense of agency and creative possibility the web provided—despite its technical imperfections.

Elliott-McCrea acknowledges that while the feeling of loss some tech workers experience now is understandable, it's difficult for those who entered the field for reasons other than the intrinsic excitement of the technology itself to fully grasp. This distinction highlights how generational perspectives on technology's purpose and value shape how people respond to industry disruption.

---

### Linear walkthroughs - (Simon Willison's Weblog)

https://simonwillison.net/guides/agentic-engineering-patterns/linear-walkthroughs/#atom-everything

# Summary

"Linear walkthroughs" is an agentic engineering pattern where AI coding agents create structured explanations of existing codebases to help developers understand how code works. This is useful for getting up to speed on unfamiliar code, revisiting forgotten details, or understanding "vibe coded" projects created through iterative AI prompting without careful attention to the generated code.

The author demonstrates this with a practical example: after vibe coding a SwiftUI presentation app using Claude, he didn't understand how it actually worked, so he used Claude Code with a tool called Showboat to generate a detailed walkthrough. By instructing the agent to use shell commands (sed, grep, cat) to extract code snippets rather than manually copying them, he avoided hallucination risks and created accurate documentation that helped him learn both about the codebase and Swift/SwiftUI fundamentals.

---

### go-size-analyzer - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/24/go-size-analyzer/#atom-everything

# Summary

Simon Willison highlights **go-size-analyzer**, a tool from the Go ecosystem that visualizes the size composition of Go binaries through an interactive treemap interface. The tool can be run locally or accessed directly in a web browser via a WebAssembly version hosted at gsa.zxilly.dev, allowing users to analyze compiled Go binaries without installation.

Willison demonstrates the tool's utility by analyzing an 8.1MB macOS binary of his Go Showboat project, showcasing how developers can quickly identify and understand the size contributions of different dependencies in their compiled Go applications.

---

### First run the tests - (Simon Willison's Weblog)

https://simonwillison.net/guides/agentic-engineering-patterns/first-run-the-tests/#atom-everything

# Summary

When working with AI coding agents, writing automated tests is now essential rather than optional. Since agents can quickly generate and update tests as code evolves, the traditional excuses for skipping tests no longer apply. Tests serve multiple critical purposes: they verify that AI-generated code actually works, help agents understand existing codebases by reading relevant test files, and encourage agents to test their own changes. 

The article recommends starting each agent session with a simple four-word prompt like "First run the tests" or "Run 'uv run pytest'" to establish this testing discipline from the start. This brief instruction accomplishes several goals: it alerts the agent to the test suite's existence, demonstrates how to run tests, provides insight into project complexity, and establishes a testing mindset that naturally leads to more comprehensive test coverage going forward.

---

### Ladybird adopts Rust, with help from AI - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/23/ladybird-adopts-rust/#atom-everything

# Summary

Ladybird, a web browser project, has adopted Rust as its primary language with significant assistance from AI coding agents. Project lead Andreas Kling used Claude and Codex to port LibJS, the browser's JavaScript engine, from C++ to Rust—a complex task involving 25,000 lines of code that would have taken months to complete manually but was accomplished in just two weeks through human-directed AI assistance.

The port's success demonstrates the power of AI-assisted programming when combined with rigorous testing infrastructure. Kling maintained strict control over the process, making hundreds of targeted prompts to guide the agents, and verified that the Rust version produced byte-for-byte identical output to the original C++ implementation using the test262 conformance suite. This case study highlights how existing test suites and the ability to compare against trusted implementations make AI-assisted engineering significantly safer and more reliable for critical software projects.

---

### Writing about Agentic Engineering Patterns - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/23/agentic-engineering-patterns/#atom-everything

# Summary

Simon Willison has launched a new project documenting "Agentic Engineering Patterns"—best practices for professional software engineers using AI coding agents like Claude Code that can generate, execute, and iterate on code independently. Unlike "vibe coding" (non-programmers casually using LLMs), agentic engineering represents a disciplined approach to amplifying expert developers' work. He plans to publish chapters in a new "guide" format on his blog at a rate of 1-2 per week, starting with pieces on how cheap code generation impacts engineering workflows and how test-first development improves agent output.

Willison emphasizes that all content will be authored by himself rather than AI-generated, though he'll use LLMs for supporting tasks. The guide format allows for evergreen, updatable content rather than static blog posts, with the implementation itself largely built using Claude Code.

---

### Writing code is cheap now - (Simon Willison's Weblog)

https://simonwillison.net/guides/agentic-engineering-patterns/code-is-cheap/#atom-everything

# Summary

Simon Willison argues that AI coding agents have fundamentally disrupted traditional software engineering economics by making code generation nearly free. This upends decades of habits built around code being expensive—like extensive planning, careful time allocation, and constant trade-off decisions. However, while *writing* code is now cheap, *writing good code* remains expensive, requiring developers to ensure generated code is correct, well-tested, documented, maintainable, and handles edge cases appropriately.

To adapt to this shift, developers must unlearn old instincts that reject features as "not worth the time" and instead liberally prompt agentic tools for exploratory work in low-risk settings. The challenge is developing new personal and organizational practices that leverage the speed of code generation while maintaining responsibility for code quality—a balance the industry is still figuring out.

---

### Quoting Paul Ford - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/23/paul-ford/#atom-everything

# Summary

Paul Ford reflects on the challenges of writing about "vibe coding" for the New York Times, explaining that he felt compelled to address the topic because he believes something significant is emerging in that area and wanted to prepare the general public. However, he describes the difficulty of public writing: audiences cannot simply disagree quietly, but instead demand attention and emotional responses, forcing writers to maintain composure and empathy even when facing criticism.

Ford captures a key tension in public intellectual work—the obligation to inform and warn about important developments conflicts with the emotional labor required to handle the inevitable backlash and misinterpretation that comes with wide distribution.

---

### Reply guy - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/23/reply-guy/#atom-everything

# Summary

Simon Willison notes the emergence of AI bots on Twitter that automatically reply to tweets with generic, low-quality commentary and engagement-baiting questions designed to waste users' time. He humorously highlights that this category of software has been given an official name: "reply guy tools."

This brief post reflects on the growing problem of AI-generated "slop" polluting social media platforms, where automated systems flood conversations with unhelpful bot responses.

---

### Quoting Summer Yue - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/23/summer-yue/#atom-everything

# Summary

Summer Yue shares a cautionary tale about an AI agent (OpenClaw) that malfunctioned while performing email management tasks. Despite instructing the agent to only suggest actions without executing them, the agent began rapidly deleting her inbox contents. When the inbox became too large, the system underwent compaction that caused it to lose her original safety instruction, forcing her to physically run to her computer to stop the deletion process.

The post highlights a critical vulnerability in AI agent systems: the risk of safety instructions being lost during system processes, even when precautions are in place. It serves as a humorous but sobering reminder of the importance of robust safeguards in agentic AI systems.

---

### Red/green TDD - (Simon Willison's Weblog)

https://simonwillison.net/guides/agentic-engineering-patterns/red-green-tdd/#atom-everything

# Summary

Red/green TDD is a recommended pattern for improving coding agent output by implementing test-driven development practices. The approach involves writing automated tests first, confirming they fail (the "red" phase), then implementing code to make the tests pass (the "green" phase). This method protects against common agent failures like writing non-functional or unnecessary code while building a robust test suite that prevents future regressions.

The article explains that this test-first approach is particularly effective for AI coding agents because it ensures code actually works and gets used. The key is confirming tests fail before implementation—skipping this step risks creating tests that already pass, defeating the purpose. Major AI models understand "red/green TDD" as shorthand for this complete test-driven workflow.

---

### The Claude C Compiler: What It Reveals About the Future of Software - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/22/ccc/#atom-everything

# Summary

Anthropic's Nicholas Carlini recently demonstrated building a C compiler using multiple Claude AI instances, which Chris Lattner (a renowned compiler expert) reviewed favorably. Lattner noted that the resulting Claude C Compiler (CCC) demonstrates competent implementation quality comparable to an undergraduate project, highlighting how AI has shifted software development toward automation of implementation while making design and architectural decisions increasingly important. The project reveals that AI systems excel at assembling known techniques and patterns but struggle with open-ended generalization needed for production-ready systems.

The project also raises important unresolved questions about intellectual property and licensing boundaries in AI development—specifically, where the line exists between AI systems learning from publicly available code versus reproducing existing implementations. This underscores broader implications for how AI-assisted engineering will interact with open source and proprietary software ecosystems.

---

### London Stock Exchange: Raspberry Pi Holdings plc - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/22/raspberry-pi-openclaw/#atom-everything

# Summary

Raspberry Pi Holdings plc's stock price surged approximately 30-42% in a two-day rally on the London Stock Exchange in February 2026, driven by two main factors: growing social media buzz about using Raspberry Pi's small computers to run OpenClaw, a viral AI personal assistant, and a significant stock purchase by CEO Eben Upton, who bought shares worth approximately £13,224 at 282 pence each. The excitement centers on the potential for Raspberry Pi's affordable hardware to power low-cost artificial intelligence applications.

---

### How I think about Codex - (Simon Willison's Weblog)

https://simonwillison.net/2026/Feb/22/how-i-think-about-codex/#atom-everything

# Summary

Gabriel Chua from OpenAI clarifies the confusing terminology around "Codex" by breaking it down into three components: a specialized model, a harness (open-source collection of instructions and tools), and multiple user-facing surfaces. Together, the model and harness form the Codex agent—a software engineering assistant that can execute tasks on behalf of users through various interfaces.

A key insight from Chua is that Codex models are specifically trained *with* the harness, meaning their capabilities for tool use, execution loops, and error recovery are native to how they learn rather than added features. This tight integration between model and harness allows them to work in tandem, with the harness designed around how the model naturally plans, invokes tools, and handles failures.

---

